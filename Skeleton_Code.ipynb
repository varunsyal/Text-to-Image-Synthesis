{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import pickle\n",
    "from random import *\n",
    "import gc\n",
    "from torch.distributions.multivariate_normal import MultivariateNormal\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Data on System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_input(dataset='CUB', process='resize'):\n",
    "    # Define File Destinations\n",
    "    test_desc_fname = dataset+'/desc/test/char-CNN-RNN-embeddings.npy'\n",
    "    train_desc_fname = dataset+'/desc/train/char-CNN-RNN-embeddings.npy'\n",
    "    \n",
    "    test_files_fname = dataset+'/desc/test/filenames.pickle'\n",
    "    train_files_fname = dataset+'/desc/train/filenames.pickle'\n",
    "    \n",
    "    test_img_dir = dataset+'/images/'\n",
    "    train_img_dir = dataset+'/images/'\n",
    "    \n",
    "    train_s1_data = []\n",
    "    test_s1_data = []\n",
    "    train_s2_data = []\n",
    "    test_s2_data = []\n",
    "    \n",
    "    #Load Training Data\n",
    "    print('Loading Training Data...')\n",
    "    train_embed = np.load(train_desc_fname)\n",
    "    train_embed_shape = train_embed.shape\n",
    "    \n",
    "    with open(train_files_fname,'rb') as file:\n",
    "        dat = pickle.load(file)\n",
    "    for i in range(len(dat)):\n",
    "        img = cv2.imread(train_img_dir+dat[i]+'.jpg',1)\n",
    "        if process == 'resize':\n",
    "            img_s1 = cv2.resize(img,(64,64),interpolation=cv2.INTER_AREA)\n",
    "            img_s2 = cv2.resize(img,(256,256),interpolation=cv2.INTER_AREA)\n",
    "        else:\n",
    "            pass\n",
    "        for j in range(train_embed_shape[1]):\n",
    "            train_s1_data.append((img_s1,train_embed[i,j,:],1))\n",
    "            \n",
    "            neg_img = randint(0,train_embed_shape[0]-1)\n",
    "   \n",
    "            while neg_img == i:\n",
    "                neg_img = randint(0,train_embed_shape[0]-1)\n",
    "            neg_idx = randint(0,train_embed_shape[1]-1)\n",
    "            train_s2_data.append((img_s2,train_embed[i,j,:],1))\n",
    "            train_s2_data.append((img_s2,train_embed[neg_img,neg_idx,:],0))\n",
    "        \n",
    "        if i%1000 == 0:\n",
    "            print(i)\n",
    "        \n",
    "    #Load Testing Data\n",
    "    print('Loading Testing Data...')\n",
    "    test_embed = np.load(test_desc_fname)\n",
    "    test_embed_shape = test_embed.shape\n",
    "    \n",
    "    with open(test_files_fname,'rb') as file:\n",
    "        dat = pickle.load(file)\n",
    "    for i in range(len(dat)):\n",
    "        img = cv2.imread(test_img_dir+dat[i]+'.jpg',1)\n",
    "        if process == 'resize':\n",
    "            img_s1 = cv2.resize(img,(64,64),interpolation=cv2.INTER_AREA)\n",
    "            img_s2 = cv2.resize(img,(256,256),interpolation=cv2.INTER_AREA)\n",
    "        else:\n",
    "            pass\n",
    "        for j in range(test_embed_shape[1]):\n",
    "            test_s1_data.append((img_s1,test_embed[i,j,:],1))\n",
    "            \n",
    "            neg_img = randint(0,test_embed_shape[0]-1)\n",
    "            while neg_img == i:\n",
    "                neg_img = randint(0,test_embed_shape[0]-1)\n",
    "            neg_idx = randint(0,test_embed_shape[1]-1)\n",
    "            test_s2_data.append((img_s2,test_embed[i,j,:],1))\n",
    "            test_s2_data.append((img_s2,test_embed[neg_img,neg_idx,:],0))\n",
    "            \n",
    "        if i%1000 == 0:\n",
    "            print(i)\n",
    "    \n",
    "    return train_s1_data, test_s1_data, train_s2_data, test_s2_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_s1_data, test_s1_data, train_s2_data, test_s2_data = read_input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train_s1_data))\n",
    "print(len(test_s1_data))\n",
    "print(len(train_s2_data))\n",
    "print(len(test_s2_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## StackGAN Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_gen():\n",
    "    pass\n",
    "    \n",
    "def loss_disc():\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upSample(c_in, c_out):\n",
    "    mod = torch.nn.Sequential(\n",
    "        torch.nn.Upsample(scale_factor=2, mode='nearest'),\n",
    "        torch.nn.Conv2d(c_in, c_out, kernel_size = 3, stride = 1, padding = 1, bias = False),\n",
    "        torch.nn.BatchNorm2d(c_out),\n",
    "        torch.nn.ReLU(inplace=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class cond_aug(torch.nn.Module):\n",
    "    def __init__(self, embedding_dim=1024, cond_dim=128):\n",
    "        super(cond_aug,self).__init__()\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.cond_dim = cond_dim\n",
    "        \n",
    "        self.fc_mu = torch.nn.Linear(self.embedding_dim, self.cond_dim)\n",
    "        self.fc_sigma = torch.nn.Linear(self.embedding_dim, self.cond_dim)\n",
    "        \n",
    "        torch.nn.init.xavier_normal(self.fc_mu.weight)\n",
    "        torch.nn.init.xavier_normal(self.fc_sigma.weight)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        mu = torch.nn.ReLU(self.fc_mu(x))\n",
    "        sigma = torch.nn.ReLU(self.fc_sigma(x))\n",
    "        dist = MultivariateNormal(torch.zeros(self.cond_dim), torch.eye(self.cond_dim))\n",
    "        eps = Variable(dist.sample()).view(1,-1)\n",
    "        \n",
    "        c = mu + (sigma * eps)\n",
    "        return mu, sigma, c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class stage1_gen(torch.nn.Module):\n",
    "    def __init__(self, embedding_dim=1024, cond_dim=128, noise_dim=100, ups_input_dim=1024 ):\n",
    "        super(stage1_gen,self).__init__()\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.cond_dim = cond_dim\n",
    "        self.noise_dim = noise_dim\n",
    "        self.ups_input_dim = ups_input_dim\n",
    "        self.conc_dim = self.cond_dim + self.noise_dim\n",
    "        \n",
    "        self.dist = MultivariateNormal(torch.zeros(self.noise_dim), torch.eye(self.noise_dim))\n",
    "        self.augm = cond_aug(self.embedding_dim, self.cond_dim)\n",
    "        self.ups_input = torch.nn.Sequential(\n",
    "                    torch.nn.Linear(self.conc_dim, self.ups_input_dim*4*4, bias=False),\n",
    "                    torch.nn.BatchNorm1d(self.ups_input_dim*4*4),\n",
    "                    torch.nn.ReLU(inplace=True))\n",
    "        self.upsample1 = upSample(self.ups_input_dim,self.ups_input_dim//2)     \n",
    "        self.upsample2 = upSample(self.ups_input_dim//2,self.ups_input_dim//4)\n",
    "        self.upsample3 = upSample(self.ups_input_dim//4,self.ups_input_dim//8)\n",
    "        self.upsample4 = upSample(self.ups_input_dim//8,self.ups_input_dim//16)\n",
    "        self.gen_img = torch.nn.Sequential(\n",
    "                torch.nn.Conv2d(self.ups_input_dim//16, 3, kernel_size = 3, stride = 1, padding = 1, bias = False),\n",
    "                torch.nn.Tanh())\n",
    "        \n",
    "    def forward(self, x):\n",
    "        z = Variable(self.dist.sample()).view(1,-1)\n",
    "        mu, sigma, c = self.augm(x).view(1,-1)\n",
    "        inp = torch.cat((c,z),1)\n",
    "        \n",
    "        x = self.ups_input(inp).view(-1,self.ups_input_dim,4,4)\n",
    "        x = self.upsample1(x)\n",
    "        x = self.upsample2(x)\n",
    "        x = self.upsample3(x)\n",
    "        x = self.upsample4(x)\n",
    "        out = self.gen_img(x)\n",
    "        \n",
    "        return mu, sigma, out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class stage1_disc(torch.nn.Module):\n",
    "    def __init__(self, cond_dim=128, down_dim=64):\n",
    "        super(stage1_disc,self).__init__()\n",
    "        self.cond_dim = cond_dim\n",
    "        self.down_dim = down_dim\n",
    "        \n",
    "        self.enc_img = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(3, self.down_dim, kernel_size = 4, stride = 2, padding = 1, bias = False),\n",
    "            torch.nn.LeakyReLU(0.2, inplace=True),\n",
    "            torch.nn.Conv2d(self.down_dim, self.down_dim*2, kernel_size = 4, stride = 2, padding = 1, bias = False),\n",
    "            torch.nn.BatchNorm2d(self.down_dim*2),\n",
    "            torch.nn.LeakyReLU(0.2, inplace=True),\n",
    "            torch.nn.Conv2d(self.down_dim*2, self.down_dim*4, kernel_size = 4, stride = 2, padding = 1, bias = False),\n",
    "            torch.nn.BatchNorm2d(self.down_dim*4),\n",
    "            torch.nn.LeakyReLU(0.2, inplace=True),\n",
    "            torch.nn.Conv2d(self.down_dim*4, self.down_dim*8, kernel_size = 4, stride = 2, padding = 1, bias = False),\n",
    "            torch.nn.BatchNorm2d(self.down_dim*8),\n",
    "            torch.nn.LeakyReLU(0.2, inplace=True))\n",
    "        \n",
    "        self.get_logits = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(self.down_dim*8+self.cond_dim, self.down_dim*8, kernel_size = 3, stride = 1, padding = 1, bias = False),\n",
    "            torch.nn.BatchNorm2d(self.down_dim*8),\n",
    "            torch.nn.LeakyReLU(0.2, inplace=True),\n",
    "            torch.nn.Conv2d(self.down_dim*8, 1, kernel_size = 4, stride = 4),\n",
    "            torch.nn.Sigmoid())\n",
    "        \n",
    "    def forward(self, image, cond_vec):\n",
    "        x = self.enc_img(image)\n",
    "        y = cond_vec.view(-1, self.cond_dim, 1, 1)\n",
    "        y = y.repeat(1,1,4,4)\n",
    "        z = torch.cat((x,y),1)\n",
    "        out = self.get_logits(z).view(-1)\n",
    "        \n",
    "        return out"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
