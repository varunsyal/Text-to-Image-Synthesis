{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import pickle\n",
    "from random import *\n",
    "import gc\n",
    "from torch.distributions.multivariate_normal import MultivariateNormal\n",
    "import torch.optim as optim\n",
    "from time import gmtime, strftime\n",
    "import os\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Data on System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_input(dataset='CUB', process='resize'):\n",
    "    # Define File Destinations\n",
    "    test_desc_fname = dataset+'/desc/test/char-CNN-RNN-embeddings.npy'\n",
    "    train_desc_fname = dataset+'/desc/train/char-CNN-RNN-embeddings.npy'\n",
    "    \n",
    "    test_files_fname = dataset+'/desc/test/filenames.pickle'\n",
    "    train_files_fname = dataset+'/desc/train/filenames.pickle'\n",
    "    \n",
    "    test_img_dir = dataset+'/images/'\n",
    "    train_img_dir = dataset+'/images/'\n",
    "    \n",
    "    train_s1_data = []\n",
    "    test_s1_data = []\n",
    "    train_s2_data = []\n",
    "    test_s2_data = []\n",
    "    \n",
    "    #Load Training Data\n",
    "    print('Loading Training Data...')\n",
    "    train_embed = np.load(train_desc_fname)\n",
    "    train_embed_shape = train_embed.shape\n",
    "    \n",
    "    with open(train_files_fname,'rb') as file:\n",
    "        dat = pickle.load(file)\n",
    "    for i in range(len(dat)):\n",
    "        img = cv2.imread(train_img_dir+dat[i]+'.jpg',1)\n",
    "        if process == 'resize':\n",
    "            img_s1 = cv2.resize(img,(64,64),interpolation=cv2.INTER_AREA)\n",
    "            img_s2 = cv2.resize(img,(256,256),interpolation=cv2.INTER_AREA)\n",
    "        else:\n",
    "            pass\n",
    "        img_s1 = np.transpose(img_s1,(2,0,1))\n",
    "        img_s2 = np.transpose(img_s2,(2,0,1))\n",
    "        for j in range(train_embed_shape[1]):\n",
    "            neg_img = randint(0,train_embed_shape[0]-1)\n",
    "            while neg_img == i:\n",
    "                neg_img = randint(0,train_embed_shape[0]-1)\n",
    "            neg_idx = randint(0,train_embed_shape[1]-1)\n",
    "            train_s1_data.append((img_s1,train_embed[i,j,:],1))\n",
    "            train_s1_data.append((img_s1,train_embed[neg_img,neg_idx,:],0))\n",
    "            train_s2_data.append((img_s2,train_embed[i,j,:],1))\n",
    "            train_s2_data.append((img_s2,train_embed[neg_img,neg_idx,:],0))\n",
    "        \n",
    "        if i%1000 == 0:\n",
    "            print(i)\n",
    "        \n",
    "    #Load Testing Data\n",
    "    print('Loading Testing Data...')\n",
    "    test_embed = np.load(test_desc_fname)\n",
    "    test_embed_shape = test_embed.shape\n",
    "    \n",
    "    with open(test_files_fname,'rb') as file:\n",
    "        dat = pickle.load(file)\n",
    "    for i in range(len(dat)):\n",
    "        img = cv2.imread(test_img_dir+dat[i]+'.jpg',1)\n",
    "        if process == 'resize':\n",
    "            img_s1 = cv2.resize(img,(64,64),interpolation=cv2.INTER_AREA)\n",
    "            img_s2 = cv2.resize(img,(256,256),interpolation=cv2.INTER_AREA)\n",
    "        else:\n",
    "            pass\n",
    "        img_s1 = np.transpose(img_s1,(2,0,1))\n",
    "        img_s2 = np.transpose(img_s2,(2,0,1))\n",
    "        for j in range(test_embed_shape[1]):\n",
    "            neg_img = randint(0,test_embed_shape[0]-1)\n",
    "            while neg_img == i:\n",
    "                neg_img = randint(0,test_embed_shape[0]-1)\n",
    "            neg_idx = randint(0,test_embed_shape[1]-1)\n",
    "            test_s1_data.append((img_s1,test_embed[i,j,:],1))\n",
    "            test_s1_data.append((img_s1,test_embed[neg_img,neg_idx,:],0))\n",
    "            test_s2_data.append((img_s2,test_embed[i,j,:],1))\n",
    "            test_s2_data.append((img_s2,test_embed[neg_img,neg_idx,:],0))\n",
    "            \n",
    "        if i%1000 == 0:\n",
    "            print(i)\n",
    "    \n",
    "    return train_s1_data, test_s1_data, train_s2_data, test_s2_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_s1_data, test_s1_data, train_s2_data, test_s2_data = read_input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train_s1_data))\n",
    "print(len(test_s1_data))\n",
    "print(len(train_s2_data))\n",
    "print(len(test_s2_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## StackGAN Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_criterion = torch.nn.BCELoss()\n",
    "\n",
    "def KL_Loss(mu, sigma):\n",
    "    kl_ele = mu.pow(2).add_(sigma.pow(2)).mul_(-1).add_(1).add_(sigma.pow(2).log_())\n",
    "    kl = torch.mean(kl_ele).mul_(-0.5)\n",
    "    return kl\n",
    "\n",
    "def loss_gen(disc_fake, mu, sigma, kl_lambda):\n",
    "    g_fake = -loss_criterion(disc_fake, Variable(torch.FloatTensor([0]), requires_grad=False).cuda())\n",
    "    kl_loss = KL_Loss(mu, sigma)\n",
    "    g_total = g_fake + (kl_lambda*kl_loss)\n",
    "    return g_total\n",
    "    \n",
    "def loss_disc(disc_real, disc_fake, disc_wrong):\n",
    "    d_real = loss_criterion(disc_real, Variable(torch.FloatTensor([1]), requires_grad=False).cuda())\n",
    "    d_fake = loss_criterion(disc_fake, Variable(torch.FloatTensor([0]), requires_grad=False).cuda())\n",
    "    d_wrong = loss_criterion(disc_wrong, Variable(torch.FloatTensor([0]), requires_grad=False).cuda())\n",
    "    d_total = d_real + ((d_fake + d_wrong)*0.5)\n",
    "    return d_total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upSample(c_in, c_out):\n",
    "    mod = torch.nn.Sequential(\n",
    "        torch.nn.Upsample(scale_factor=2, mode='nearest'),\n",
    "        torch.nn.Conv2d(c_in, c_out, kernel_size = 3, stride = 1, padding = 1, bias = False),\n",
    "        torch.nn.BatchNorm2d(c_out),\n",
    "        torch.nn.ReLU(inplace=True))\n",
    "    return mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class cond_aug(torch.nn.Module):\n",
    "    def __init__(self, embedding_dim=1024, cond_dim=128):\n",
    "        super(cond_aug,self).__init__()\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.cond_dim = cond_dim\n",
    "        \n",
    "        self.fc_mu = torch.nn.Linear(self.embedding_dim, self.cond_dim)\n",
    "        self.fc_sigma = torch.nn.Linear(self.embedding_dim, self.cond_dim)\n",
    "        \n",
    "        torch.nn.init.xavier_normal_(self.fc_mu.weight)\n",
    "        torch.nn.init.xavier_normal_(self.fc_sigma.weight)\n",
    "        self.relu = torch.nn.ReLU(inplace=True)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        mu = self.relu(self.fc_mu(x))\n",
    "        logvar = self.relu(self.fc_sigma(x))\n",
    "        sigma = logvar.mul(0.5).exp_()\n",
    "        dist = MultivariateNormal(torch.zeros(self.cond_dim).cuda(), torch.eye(self.cond_dim).cuda())\n",
    "        eps = Variable(dist.sample()).cuda().view(1,-1)\n",
    "        \n",
    "        c = mu + (sigma * eps)\n",
    "        return mu, sigma, c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResBlock(torch.nn.Module):\n",
    "    def __init__(self, channel_num):\n",
    "        super(ResBlock, self).__init__()\n",
    "        self.block = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(channel_num, channel_num, kernel_size = 3, stride = 1, padding = 1, bias = False),\n",
    "            torch.nn.BatchNorm2d(channel_num),\n",
    "            torch.nn.ReLU(True),\n",
    "            torch.nn.Conv2d(channel_num, channel_num, kernel_size = 3, stride = 1, padding = 1, bias = False),\n",
    "            torch.nn.BatchNorm2d(channel_num))\n",
    "        self.relu = torch.nn.ReLU(inplace=True)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.block(x)\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class stage1_gen(torch.nn.Module):\n",
    "    def __init__(self, embedding_dim=1024, cond_dim=128, noise_dim=100, ups_input_dim=1024 ):\n",
    "        super(stage1_gen,self).__init__()\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.cond_dim = cond_dim\n",
    "        self.noise_dim = noise_dim\n",
    "        self.ups_input_dim = ups_input_dim\n",
    "        self.conc_dim = self.cond_dim + self.noise_dim\n",
    "        \n",
    "        self.dist = MultivariateNormal(torch.zeros(self.noise_dim).cuda(), torch.eye(self.noise_dim).cuda())\n",
    "        self.augm = cond_aug(self.embedding_dim, self.cond_dim)\n",
    "        self.ups_input = torch.nn.Sequential(\n",
    "                    torch.nn.Linear(self.conc_dim, self.ups_input_dim*4*4, bias=False),\n",
    "#                     torch.nn.BatchNorm1d(self.ups_input_dim*4*4).cuda())\n",
    "                    torch.nn.ReLU(inplace=True))\n",
    "        self.upsample1 = upSample(self.ups_input_dim,self.ups_input_dim//2)     \n",
    "        self.upsample2 = upSample(self.ups_input_dim//2,self.ups_input_dim//4)\n",
    "        self.upsample3 = upSample(self.ups_input_dim//4,self.ups_input_dim//8)\n",
    "        self.upsample4 = upSample(self.ups_input_dim//8,self.ups_input_dim//16)\n",
    "        self.gen_img = torch.nn.Sequential(\n",
    "                torch.nn.Conv2d(self.ups_input_dim//16, 3, kernel_size = 3, stride = 1, padding = 1, bias = False),\n",
    "                torch.nn.Tanh())\n",
    "        \n",
    "    def forward(self, x):\n",
    "        z = Variable(self.dist.sample()).cuda().view(1,-1)\n",
    "        mu, sigma, c = self.augm(x)\n",
    "        c = c.view(1,-1)\n",
    "        inp = torch.cat((c,z),1)\n",
    "        \n",
    "        x = self.ups_input(inp)\n",
    "        x = x.view(-1,self.ups_input_dim,4,4)\n",
    "        x = self.upsample1(x)\n",
    "        x = self.upsample2(x)\n",
    "        x = self.upsample3(x)\n",
    "        x = self.upsample4(x)\n",
    "        fake_img = self.gen_img(x)\n",
    "        \n",
    "        return fake_img, mu, sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class stage1_disc(torch.nn.Module):\n",
    "    def __init__(self, cond_dim=128, down_dim=64):\n",
    "        super(stage1_disc,self).__init__()\n",
    "        self.cond_dim = cond_dim\n",
    "        self.down_dim = down_dim\n",
    "        \n",
    "        self.enc_img = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(3, self.down_dim, kernel_size = 4, stride = 2, padding = 1, bias = False),\n",
    "            torch.nn.LeakyReLU(0.2, inplace=True),\n",
    "            torch.nn.Conv2d(self.down_dim, self.down_dim*2, kernel_size = 4, stride = 2, padding = 1, bias = False),\n",
    "            torch.nn.BatchNorm2d(self.down_dim*2),\n",
    "            torch.nn.LeakyReLU(0.2, inplace=True),\n",
    "            torch.nn.Conv2d(self.down_dim*2, self.down_dim*4, kernel_size = 4, stride = 2, padding = 1, bias = False),\n",
    "            torch.nn.BatchNorm2d(self.down_dim*4),\n",
    "            torch.nn.LeakyReLU(0.2, inplace=True),\n",
    "            torch.nn.Conv2d(self.down_dim*4, self.down_dim*8, kernel_size = 4, stride = 2, padding = 1, bias = False),\n",
    "            torch.nn.BatchNorm2d(self.down_dim*8),\n",
    "            torch.nn.LeakyReLU(0.2, inplace=True))\n",
    "        \n",
    "        self.get_logits = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(self.down_dim*8+self.cond_dim, self.down_dim*8, kernel_size = 3, stride = 1, padding = 1, bias = False),\n",
    "            torch.nn.BatchNorm2d(self.down_dim*8),\n",
    "            torch.nn.LeakyReLU(0.2, inplace=True),\n",
    "            torch.nn.Conv2d(self.down_dim*8, 1, kernel_size = 4, stride = 4),\n",
    "            torch.nn.Sigmoid())\n",
    "        \n",
    "    def forward(self, image, cond_vec):\n",
    "        x = self.enc_img(image)\n",
    "        y = cond_vec.view(-1, self.cond_dim, 1, 1)\n",
    "        y = y.repeat(1,1,4,4)\n",
    "        z = torch.cat((x,y),1) # N x (128 + 512) x 4 x 4\n",
    "        out = self.get_logits(z).view(-1)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class stage2_gen(torch.nn.Module):\n",
    "    def __init__(self, down_dim=128, embedding_dim=1024, cond_dim=128, num_residuals=4):\n",
    "        super(stage2_gen,self).__init__()\n",
    "        self.down_dim = down_dim\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.cond_dim = cond_dim\n",
    "        self.downsampler = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(3, self.down_dim, kernel_size = 3, stride = 1, padding = 1, bias = False),\n",
    "            torch.nn.ReLU(inplace=True),\n",
    "            torch.nn.Conv2d(self.down_dim, self.down_dim * 2, kernel_size = 4, stride = 2, padding = 1, bias=False),\n",
    "            torch.nn.BatchNorm2d(self.down_dim * 2),\n",
    "            torch.nn.ReLU(inplace=True),\n",
    "            torch.nn.Conv2d(self.down_dim * 2, self.down_dim * 4, kernel_size = 4, stride = 2, padding = 1, bias=False),\n",
    "            torch.nn.BatchNorm2d(self.down_dim * 4),\n",
    "            torch.nn.ReLU(inplace=True))\n",
    "        \n",
    "        self.augm = cond_aug(self.embedding_dim, self.cond_dim)\n",
    "        \n",
    "        self.joint_proc = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(self.down_dim * 4 + self.cond_dim, self.down_dim * 4, kernel_size = 3, stride = 1, padding = 1, bias = False),\n",
    "            torch.nn.BatchNorm2d(self.down_dim * 4),\n",
    "            torch.nn.ReLU(True))\n",
    "        \n",
    "        self.layers = []\n",
    "        for i in range(num_residuals):\n",
    "            self.layers.append(ResBlock(self.down_dim * 4))\n",
    "        self.residual = torch.nn.Sequential(*self.layers)\n",
    "        \n",
    "        self.upsample1 = upSample(self.down_dim * 4, self.down_dim * 2)\n",
    "        self.upsample2 = upSample(self.down_dim * 2, self.down_dim)\n",
    "        self.upsample3 = upSample(self.down_dim, self.down_dim // 2)\n",
    "        self.upsample4 = upSample(self.down_dim // 2, self.down_dim // 4)\n",
    "        self.gen_img = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(self.down_dim // 4, 3, kernel_size = 3, stride = 1, padding = 1, bias = False),\n",
    "            torch.nn.Tanh())\n",
    "\n",
    "        \n",
    "        \n",
    "    def forward(self, text_embedding, stage1_image):\n",
    "        encoded_img = self.downsampler(stage1_image) # --> N x 512 x 16 x 16\n",
    "        mu, sigma, c = self.augm(text_embedding)\n",
    "        c = c.view(-1, self.cond_dim, 1, 1) # --> N x 128 x 1 x 1\n",
    "        c = c.repeat(1, 1, 16, 16) # --> N x 128 x 16 x 16\n",
    "        conc_inp = torch.cat([encoded_img, c], 1) # --> N x 640 x 16 x 16\n",
    "        \n",
    "        conc_out = self.joint_proc(conc_inp) # --> N x 512 x 16 x 16\n",
    "        conc_out = self.residual(conc_out)   # --> N x 512 x 16 x 16\n",
    "        \n",
    "        conc_out = self.upsample1(conc_out) # --> N x 256 x 32 x 32\n",
    "        conc_out = self.upsample2(conc_out) # --> N x 128 x 64 x 64\n",
    "        conc_out = self.upsample3(conc_out) # --> N x 64 x 128 x 128\n",
    "        conc_out = self.upsample4(conc_out) # --> N x 32 x 256 x 256\n",
    "\n",
    "        fake_img = self.gen_img(conc_out) # --> N x 3 x 256 x 256\n",
    "        return fake_img, mu, sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class stage2_disc(torch.nn.Module):\n",
    "    def __init__(self, cond_dim=128, down_dim=64):\n",
    "        super(stage2_disc,self).__init__()\n",
    "        self.cond_dim = cond_dim\n",
    "        self.down_dim = down_dim\n",
    "        \n",
    "        self.enc_img = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(3, self.down_dim, kernel_size = 4, stride = 2, padding = 1, bias = False),\n",
    "            torch.nn.LeakyReLU(0.2, inplace=True),\n",
    "            torch.nn.Conv2d(self.down_dim, self.down_dim*2, kernel_size = 4, stride = 2, padding = 1, bias = False),\n",
    "            torch.nn.BatchNorm2d(self.down_dim*2),\n",
    "            torch.nn.LeakyReLU(0.2, inplace=True),\n",
    "            torch.nn.Conv2d(self.down_dim*2, self.down_dim*4, kernel_size = 4, stride = 2, padding = 1, bias = False),\n",
    "            torch.nn.BatchNorm2d(self.down_dim*4),\n",
    "            torch.nn.LeakyReLU(0.2, inplace=True),\n",
    "            torch.nn.Conv2d(self.down_dim*4, self.down_dim*8, kernel_size = 4, stride = 2, padding = 1, bias = False),\n",
    "            torch.nn.BatchNorm2d(self.down_dim*8),\n",
    "            torch.nn.LeakyReLU(0.2, inplace=True),\n",
    "            torch.nn.Conv2d(self.down_dim*8, self.down_dim*16, kernel_size = 4, stride = 2, padding = 1, bias = False),\n",
    "            torch.nn.BatchNorm2d(self.down_dim*16),\n",
    "            torch.nn.LeakyReLU(0.2, inplace=True),\n",
    "            torch.nn.Conv2d(self.down_dim*16, self.down_dim*32, kernel_size = 4, stride = 2, padding = 1, bias = False),\n",
    "            torch.nn.BatchNorm2d(self.down_dim*32),\n",
    "            torch.nn.LeakyReLU(0.2, inplace=True),\n",
    "            torch.nn.Conv2d(self.down_dim*32, self.down_dim*16, kernel_size = 3, stride = 1, padding = 1, bias = False),\n",
    "            torch.nn.BatchNorm2d(self.down_dim * 16),\n",
    "            torch.nn.LeakyReLU(0.2, inplace=True),\n",
    "            torch.nn.Conv2d(self.down_dim*16, self.down_dim*8, kernel_size = 3, stride = 1, padding = 1, bias = False),\n",
    "            torch.nn.BatchNorm2d(self.down_dim * 8),\n",
    "            torch.nn.LeakyReLU(0.2, inplace=True))   # 4 * 4 * ndf * 8)\n",
    "        \n",
    "        self.get_logits = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(self.down_dim*8+self.cond_dim, self.down_dim*8, kernel_size = 3, stride = 1, padding = 1, bias = False),\n",
    "            torch.nn.BatchNorm2d(self.down_dim*8),\n",
    "            torch.nn.LeakyReLU(0.2, inplace=True),\n",
    "            torch.nn.Conv2d(self.down_dim*8, 1, kernel_size = 4, stride = 4),\n",
    "            torch.nn.Sigmoid())\n",
    "        \n",
    "    def forward(self, image, cond_vec):\n",
    "        x = self.enc_img(image)\n",
    "        y = cond_vec.view(-1, self.cond_dim, 1, 1)\n",
    "        y = y.repeat(1,1,4,4)\n",
    "#         print(x.shape)\n",
    "#         print(y.shape)\n",
    "        z = torch.cat((x,y),1) # N x (128 + 512) x 4 x 4\n",
    "        out = self.get_logits(z).view(-1)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_s1(gen, disc, train_s1_data, epochs=1000, eta=0.0001, opt=optim.Adam, model_name='A_Model_Has_No_Name',\n",
    "             kl_lambda=2.0, embedding_dim=1024, cond_dim=128):\n",
    "    gen = gen.cuda()\n",
    "    disc.cuda()\n",
    "    \n",
    "    optim_gen = opt(gen.parameters(), lr=eta)\n",
    "    optim_disc = opt(disc.parameters(), lr=eta)\n",
    "        \n",
    "    l_tr_g = []\n",
    "    l_tr_d = []\n",
    "    iter_tr = []\n",
    "    \n",
    "    n_train = len(train_s1_data)\n",
    "    n_test = len(test_s1_data)\n",
    "    desc_shape = train_s1_data[0][1].shape\n",
    "    img_shape = train_s1_data[0][0].shape\n",
    "    \n",
    "    file_path = \"./observations/\"\n",
    "    directory = os.path.dirname(file_path)\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    file_path = \"./saved_models/\"\n",
    "    directory = os.path.dirname(file_path)\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    ts = strftime(\"%Y-%m-%d__%Hh%Mm%Ss_S1_\" + model_name, gmtime())\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        l_tr_g_temp = 0\n",
    "        l_tr_d_temp = 0\n",
    "        \n",
    "        ############ Training #############\n",
    "        for i in range(3):\n",
    "            print(i, '-------')\n",
    "            orig_img = Variable(torch.from_numpy(train_s1_data[i][0]).view(-1,img_shape[0],img_shape[1],img_shape[2])).type(torch.FloatTensor).cuda()\n",
    "            text = Variable(torch.from_numpy(train_s1_data[i][1]).view(-1,desc_shape[0])).cuda()\n",
    "            \n",
    "            fake_img, mu, sigma = gen(text)\n",
    "            \n",
    "            disc_real = disc(orig_img, mu)\n",
    "            disc_fake = disc(fake_img, mu)\n",
    "            augm = cond_aug(embedding_dim, cond_dim)\n",
    "            augm.cuda()\n",
    "            mu_w, _, _ = augm(Variable(torch.from_numpy(train_s1_data[i+1][1]).view(-1,desc_shape[0])).cuda())\n",
    "            disc_wrong = disc(orig_img, mu_w)\n",
    "            \n",
    "            optim_gen.zero_grad()\n",
    "            optim_disc.zero_grad()\n",
    "            \n",
    "            ld_ = loss_disc(disc_real, disc_fake, disc_wrong)         \n",
    "            ld_.backward(retain_graph=True)\n",
    "            optim_disc.step()\n",
    "            lg_ = loss_gen(disc_fake, mu, sigma, kl_lambda)\n",
    "            lg_.backward(retain_graph=True)\n",
    "            optim_gen.step()\n",
    "            \n",
    "            l_tr_g_temp += float(lg_.data)\n",
    "            l_tr_d_temp += float(ld_.data)\n",
    "            i+=1\n",
    "            del orig_img, text, fake_img, mu, sigma, augm, disc_real, disc_wrong, disc_fake, mu_w, lg_, ld_\n",
    "            \n",
    "        l_tr_g.append(l_tr_g_temp/n_train)\n",
    "        l_tr_d.append(l_tr_d_temp/n_train)\n",
    "        iter_tr.append(epoch+1)\n",
    "        l = open('./observations/Loss_S1_'+ts+'.txt','a+')\n",
    "        l.write('Epoch ' + str(epoch) + ': Generator Loss = ' + str(l_tr_g_temp/n_train) + \\\n",
    "               '         Discriminator Loss = ' + str(l_tr_d_temp/n_train)  + '\\n')\n",
    "        print('Epoch ' + str(epoch) + ': Generator Loss = ' + str(l_tr_g_temp/n_train) + \\\n",
    "               '         Discriminator Loss = ' + str(l_tr_d_temp/n_train))\n",
    "        l.close()\n",
    "    \n",
    "    return l_tr_g, l_tr_d\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_s2(gen, disc, trained_gen1, train_s2_data, epochs=1000, eta=0.0001, opt=optim.Adam, model_name='A_Model_Has_No_Name',\n",
    "             kl_lambda=2.0, embedding_dim=1024, cond_dim=128):\n",
    "    gen.cuda()\n",
    "    disc.cuda()\n",
    "    trained_gen1.cuda()\n",
    "    optim_gen = opt(gen.parameters(), lr=eta)\n",
    "    optim_disc = opt(disc.parameters(), lr=eta)\n",
    "    \n",
    "    fake_s1 = []\n",
    "    l_tr_g = []\n",
    "    l_tr_d = []\n",
    "    iter_tr = []\n",
    "    \n",
    "    n_train = len(train_s1_data)\n",
    "    n_test = len(test_s1_data)\n",
    "    desc_shape = train_s2_data[0][1].shape\n",
    "    img_shape = train_s2_data[0][0].shape\n",
    "    \n",
    "#     for i in range(len(train_s2_data)):\n",
    "#         text = Variable(torch.from_numpy(train_s2_data[i][1]).view(-1,desc_shape[0]))\n",
    "#         fake_s1.append(trained_gen1(text)[0])\n",
    "    \n",
    "    file_path = \"./observations/\"\n",
    "    directory = os.path.dirname(file_path)\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    file_path = \"./saved_models/\"\n",
    "    directory = os.path.dirname(file_path)\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    ts = strftime(\"%Y-%m-%d__%Hh%Mm%Ss_S2_\" + model_name, gmtime())\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        l_tr_g_temp = 0\n",
    "        l_tr_d_temp = 0\n",
    "        \n",
    "        ############ Training #############\n",
    "        for i in range(3):\n",
    "            print(i, '-------')\n",
    "            orig_img = Variable(torch.from_numpy(train_s2_data[i][0]).view(-1,img_shape[0],img_shape[1],img_shape[2])).type(torch.FloatTensor).cuda()\n",
    "            \n",
    "            text = Variable(torch.from_numpy(train_s2_data[i][1]).view(-1,desc_shape[0])).cuda()\n",
    "            fake_s1 = trained_gen1(text)[0]\n",
    "            fake_img, mu, sigma = gen(text, fake_s1)\n",
    "            \n",
    "            disc_real = disc(orig_img, mu)\n",
    "            disc_fake = disc(fake_img, mu)\n",
    "            augm = cond_aug(embedding_dim, cond_dim)\n",
    "            augm.cuda()\n",
    "            mu_w, _, _ = augm(Variable(torch.from_numpy(train_s2_data[i+1][1]).view(-1,desc_shape[0])).cuda())\n",
    "            disc_wrong = disc(orig_img, mu_w)\n",
    "            \n",
    "            optim_gen.zero_grad()\n",
    "            optim_disc.zero_grad()\n",
    "            \n",
    "            ld_ = loss_disc(disc_real, disc_fake, disc_wrong)         \n",
    "            ld_.backward(retain_graph=True)\n",
    "            optim_disc.step()\n",
    "            \n",
    "            lg_ = loss_gen(disc_fake, mu, sigma, kl_lambda)\n",
    "            lg_.backward(retain_graph=True)\n",
    "            optim_gen.step()\n",
    "            \n",
    "            l_tr_g_temp += float(lg_.data)\n",
    "            l_tr_d_temp += float(ld_.data)\n",
    "            i+=1\n",
    "            del orig_img, text, fake_s1, fake_img, mu, sigma, augm, disc_real, disc_wrong, disc_fake, mu_w, lg_, ld_\n",
    "            \n",
    "        l_tr_g.append(l_tr_g_temp/n_train)\n",
    "        l_tr_d.append(l_tr_d_temp/n_train)\n",
    "        iter_tr.append(epoch+1)\n",
    "        l = open('./observations/Loss_S2_'+ts+'.txt','a+')\n",
    "        l.write('Epoch ' + str(epoch) + ': Generator Loss = ' + str(l_tr_g_temp/n_train) + \\\n",
    "               '         Discriminator Loss = ' + str(l_tr_d_temp/n_train) + '\\n')\n",
    "        print('Epoch ' + str(epoch) + ': Generator Loss = ' + str(l_tr_g_temp/n_train) + \\\n",
    "               '         Discriminator Loss = ' + str(l_tr_d_temp/n_train))\n",
    "        l.close()\n",
    "    \n",
    "    return l_tr_g, l_tr_d\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = stage1_gen(embedding_dim=1024, cond_dim=128, noise_dim=100, ups_input_dim=1024)\n",
    "# gen = stage1_gen(down_dim=128, embedding_dim=1024, cond_dim=128, num_residuals=4)\n",
    "disc = stage1_disc(cond_dim=128, down_dim=64)\n",
    "train_s1(gen, disc, train_s1_data, epochs=1000, eta=0.0001, opt=optim.Adam, model_name='A_Model_Has_No_Name',\n",
    "             kl_lambda=2.0, embedding_dim=1024, cond_dim=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
