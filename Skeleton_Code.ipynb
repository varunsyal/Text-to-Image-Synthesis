{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import pickle\n",
    "from random import *\n",
    "import gc\n",
    "import torch.optim as optim\n",
    "from time import gmtime, strftime\n",
    "import os\n",
    "from PIL import Image\n",
    "import data_transform\n",
    "import torchvision.utils\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_ = strftime(\"%Y-%m-%d__%Hh%Mm%Ss\", gmtime())\n",
    "n_desc_per_img = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_criterion = torch.nn.BCELoss()\n",
    "\n",
    "def KL_Loss(mu, sigma):\n",
    "    kl_ele = mu.pow(2).add_(sigma.pow(2)).mul_(-1).add_(1).add_(sigma.pow(2).log_())\n",
    "    kl = torch.mean(kl_ele).mul_(-0.5)\n",
    "    return kl\n",
    "\n",
    "def loss_gen(disc_fake, mu, sigma, kl_lambda, batch_size):\n",
    "    g_fake = -loss_criterion(disc_fake, Variable(torch.FloatTensor([0]*batch_size), requires_grad=False).cuda())\n",
    "    kl_loss = KL_Loss(mu, sigma)\n",
    "    g_total = g_fake + (kl_lambda*kl_loss)\n",
    "    return g_total\n",
    "    \n",
    "def loss_disc(disc_real, disc_fake, disc_wrong, batch_size):\n",
    "    d_real = loss_criterion(disc_real, Variable(torch.FloatTensor([1]*batch_size), requires_grad=False).cuda())\n",
    "    d_fake = loss_criterion(disc_fake, Variable(torch.FloatTensor([0]*batch_size), requires_grad=False).cuda())\n",
    "    d_wrong = loss_criterion(disc_wrong, Variable(torch.FloatTensor([0]*batch_size), requires_grad=False).cuda())\n",
    "    d_total = d_real + ((d_fake + d_wrong)*0.5)\n",
    "    return d_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upSample(c_in, c_out):\n",
    "    mod = torch.nn.Sequential(\n",
    "        torch.nn.Upsample(scale_factor=2, mode='nearest'),\n",
    "        torch.nn.Conv2d(c_in, c_out, kernel_size = 3, stride = 1, padding = 1, bias = False),\n",
    "        torch.nn.BatchNorm2d(c_out),\n",
    "        torch.nn.ReLU(inplace=True))\n",
    "    return mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class cond_aug(torch.nn.Module):\n",
    "    def __init__(self, embedding_dim=1024, cond_dim=128):\n",
    "        super(cond_aug,self).__init__()\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.cond_dim = cond_dim\n",
    "        \n",
    "        self.fc_mu = torch.nn.Linear(self.embedding_dim, self.cond_dim)\n",
    "        self.fc_sigma = torch.nn.Linear(self.embedding_dim, self.cond_dim)\n",
    "        \n",
    "        torch.nn.init.xavier_normal_(self.fc_mu.weight)\n",
    "        torch.nn.init.xavier_normal_(self.fc_sigma.weight)\n",
    "        self.relu = torch.nn.ReLU(inplace=True)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        batch_size = x.shape[0]\n",
    "        mu = self.relu(self.fc_mu(x))\n",
    "        logvar = self.relu(self.fc_sigma(x))\n",
    "        sigma = logvar.mul(0.5).exp_()\n",
    "        dist = np.random.multivariate_normal(np.zeros(self.cond_dim),np.eye(self.cond_dim))\n",
    "        eps = Variable(torch.from_numpy(dist).type(torch.FloatTensor)).cuda().view(1,-1).repeat(batch_size,1)\n",
    "        c = mu + (sigma * eps)\n",
    "        return mu, sigma, c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResBlock(torch.nn.Module):\n",
    "    def __init__(self, channel_num):\n",
    "        super(ResBlock, self).__init__()\n",
    "        self.block = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(channel_num, channel_num, kernel_size = 3, stride = 1, padding = 1, bias = False),\n",
    "            torch.nn.BatchNorm2d(channel_num),\n",
    "            torch.nn.ReLU(True),\n",
    "            torch.nn.Conv2d(channel_num, channel_num, kernel_size = 3, stride = 1, padding = 1, bias = False),\n",
    "            torch.nn.BatchNorm2d(channel_num))\n",
    "        self.relu = torch.nn.ReLU(inplace=True)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.block(x)\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class stage1_gen(torch.nn.Module):\n",
    "    def __init__(self, embedding_dim=1024, cond_dim=128, noise_dim=100, ups_input_dim=1024):\n",
    "        super(stage1_gen,self).__init__()\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.cond_dim = cond_dim\n",
    "        self.noise_dim = noise_dim\n",
    "        self.ups_input_dim = ups_input_dim\n",
    "        self.conc_dim = self.cond_dim + self.noise_dim\n",
    "        \n",
    "        self.dist = np.random.multivariate_normal(np.zeros(self.noise_dim),np.eye(self.noise_dim))\n",
    "        self.augm = cond_aug(self.embedding_dim, self.cond_dim)\n",
    "        self.ups_input = torch.nn.Sequential(\n",
    "                    torch.nn.Linear(self.conc_dim, self.ups_input_dim*4*4, bias=False),\n",
    "                    torch.nn.BatchNorm1d(self.ups_input_dim*4*4),\n",
    "                    torch.nn.ReLU(inplace=True))\n",
    "        self.upsample1 = upSample(self.ups_input_dim,self.ups_input_dim//2)     \n",
    "        self.upsample2 = upSample(self.ups_input_dim//2,self.ups_input_dim//4)\n",
    "        self.upsample3 = upSample(self.ups_input_dim//4,self.ups_input_dim//8)\n",
    "        self.upsample4 = upSample(self.ups_input_dim//8,self.ups_input_dim//16)\n",
    "        self.gen_img = torch.nn.Sequential(\n",
    "                torch.nn.Conv2d(self.ups_input_dim//16, 3, kernel_size = 3, stride = 1, padding = 1, bias = False),\n",
    "                torch.nn.Tanh())\n",
    "        \n",
    "    def forward(self, x):\n",
    "        batch_size = x.shape[0]\n",
    "        z = Variable(torch.from_numpy(self.dist).type(torch.FloatTensor)).cuda().view(1,-1).repeat(batch_size,1)\n",
    "        mu, sigma, c = self.augm(x)\n",
    "        inp = torch.cat((c,z),1)\n",
    "        \n",
    "        x = self.ups_input(inp)\n",
    "        x = x.view(-1,self.ups_input_dim,4,4)\n",
    "        x = self.upsample1(x)\n",
    "        x = self.upsample2(x)\n",
    "        x = self.upsample3(x)\n",
    "        x = self.upsample4(x)\n",
    "        fake_img = self.gen_img(x)\n",
    "        \n",
    "        return fake_img, mu, sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class stage1_disc(torch.nn.Module):\n",
    "    def __init__(self, cond_dim=128, down_dim=64):\n",
    "        super(stage1_disc,self).__init__()\n",
    "        self.cond_dim = cond_dim\n",
    "        self.down_dim = down_dim\n",
    "        \n",
    "        self.enc_img = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(3, self.down_dim, kernel_size = 4, stride = 2, padding = 1, bias = False),\n",
    "            torch.nn.LeakyReLU(0.2, inplace=True),\n",
    "            torch.nn.Conv2d(self.down_dim, self.down_dim*2, kernel_size = 4, stride = 2, padding = 1, bias = False),\n",
    "            torch.nn.BatchNorm2d(self.down_dim*2),\n",
    "            torch.nn.LeakyReLU(0.2, inplace=True),\n",
    "            torch.nn.Conv2d(self.down_dim*2, self.down_dim*4, kernel_size = 4, stride = 2, padding = 1, bias = False),\n",
    "            torch.nn.BatchNorm2d(self.down_dim*4),\n",
    "            torch.nn.LeakyReLU(0.2, inplace=True),\n",
    "            torch.nn.Conv2d(self.down_dim*4, self.down_dim*8, kernel_size = 4, stride = 2, padding = 1, bias = False),\n",
    "            torch.nn.BatchNorm2d(self.down_dim*8),\n",
    "            torch.nn.LeakyReLU(0.2, inplace=True))\n",
    "        \n",
    "        self.get_logits = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(self.down_dim*8+self.cond_dim, self.down_dim*8, kernel_size = 3, stride = 1, padding = 1, bias = False),\n",
    "            torch.nn.BatchNorm2d(self.down_dim*8),\n",
    "            torch.nn.LeakyReLU(0.2, inplace=True),\n",
    "            torch.nn.Conv2d(self.down_dim*8, 1, kernel_size = 4, stride = 4),\n",
    "            torch.nn.Sigmoid())\n",
    "        \n",
    "    def forward(self, image, cond_vec):\n",
    "        x = self.enc_img(image)\n",
    "        y = cond_vec.view(-1, self.cond_dim, 1, 1)\n",
    "        y = y.repeat(1,1,4,4)\n",
    "        z = torch.cat((x,y),1) # N x (128 + 512) x 4 x 4\n",
    "        out = self.get_logits(z).view(-1)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class stage2_gen(torch.nn.Module):\n",
    "    def __init__(self, down_dim=128, embedding_dim=1024, cond_dim=128, num_residuals=4):\n",
    "        super(stage2_gen,self).__init__()\n",
    "        self.down_dim = down_dim\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.cond_dim = cond_dim\n",
    "        \n",
    "        self.downsampler = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(3, self.down_dim, kernel_size = 3, stride = 1, padding = 1, bias = False),\n",
    "            torch.nn.ReLU(inplace=True),\n",
    "            torch.nn.Conv2d(self.down_dim, self.down_dim * 2, kernel_size = 4, stride = 2, padding = 1, bias=False),\n",
    "            torch.nn.BatchNorm2d(self.down_dim * 2),\n",
    "            torch.nn.ReLU(inplace=True),\n",
    "            torch.nn.Conv2d(self.down_dim * 2, self.down_dim * 4, kernel_size = 4, stride = 2, padding = 1, bias=False),\n",
    "            torch.nn.BatchNorm2d(self.down_dim * 4),\n",
    "            torch.nn.ReLU(inplace=True))\n",
    "        \n",
    "        self.augm = cond_aug(self.embedding_dim, self.cond_dim)\n",
    "        \n",
    "        self.joint_proc = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(self.down_dim * 4 + self.cond_dim, self.down_dim * 4, kernel_size = 3, stride = 1, padding = 1, bias = False),\n",
    "            torch.nn.BatchNorm2d(self.down_dim * 4),\n",
    "            torch.nn.ReLU(True))\n",
    "        \n",
    "        self.layers = []\n",
    "        for i in range(num_residuals):\n",
    "            self.layers.append(ResBlock(self.down_dim * 4))\n",
    "        self.residual = torch.nn.Sequential(*self.layers)\n",
    "        \n",
    "        self.upsample1 = upSample(self.down_dim * 4, self.down_dim * 2)\n",
    "        self.upsample2 = upSample(self.down_dim * 2, self.down_dim)\n",
    "        self.upsample3 = upSample(self.down_dim, self.down_dim // 2)\n",
    "        self.upsample4 = upSample(self.down_dim // 2, self.down_dim // 4)\n",
    "        self.gen_img = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(self.down_dim // 4, 3, kernel_size = 3, stride = 1, padding = 1, bias = False),\n",
    "            torch.nn.Tanh())\n",
    "\n",
    "        \n",
    "        \n",
    "    def forward(self, text_embedding, stage1_image):\n",
    "        encoded_img = self.downsampler(stage1_image) # --> N x 512 x 16 x 16\n",
    "        mu, sigma, c = self.augm(text_embedding)\n",
    "        c = c.view(-1, self.cond_dim, 1, 1) # --> N x 128 x 1 x 1\n",
    "        c = c.repeat(1, 1, 16, 16) # --> N x 128 x 16 x 16\n",
    "        conc_inp = torch.cat([encoded_img, c], 1) # --> N x 640 x 16 x 16\n",
    "        \n",
    "        conc_out = self.joint_proc(conc_inp) # --> N x 512 x 16 x 16\n",
    "        conc_out = self.residual(conc_out)   # --> N x 512 x 16 x 16\n",
    "        \n",
    "        conc_out = self.upsample1(conc_out) # --> N x 256 x 32 x 32\n",
    "        conc_out = self.upsample2(conc_out) # --> N x 128 x 64 x 64\n",
    "        conc_out = self.upsample3(conc_out) # --> N x 64 x 128 x 128\n",
    "        conc_out = self.upsample4(conc_out) # --> N x 32 x 256 x 256\n",
    "\n",
    "        fake_img = self.gen_img(conc_out) # --> N x 3 x 256 x 256\n",
    "        return fake_img, mu, sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class stage2_disc(torch.nn.Module):\n",
    "    def __init__(self, cond_dim=128, down_dim=64):\n",
    "        super(stage2_disc,self).__init__()\n",
    "        self.cond_dim = cond_dim\n",
    "        self.down_dim = down_dim\n",
    "        \n",
    "        self.enc_img = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(3, self.down_dim, kernel_size = 4, stride = 2, padding = 1, bias = False),\n",
    "            torch.nn.LeakyReLU(0.2, inplace=True),\n",
    "            torch.nn.Conv2d(self.down_dim, self.down_dim*2, kernel_size = 4, stride = 2, padding = 1, bias = False),\n",
    "            torch.nn.BatchNorm2d(self.down_dim*2),\n",
    "            torch.nn.LeakyReLU(0.2, inplace=True),\n",
    "            torch.nn.Conv2d(self.down_dim*2, self.down_dim*4, kernel_size = 4, stride = 2, padding = 1, bias = False),\n",
    "            torch.nn.BatchNorm2d(self.down_dim*4),\n",
    "            torch.nn.LeakyReLU(0.2, inplace=True),\n",
    "            torch.nn.Conv2d(self.down_dim*4, self.down_dim*8, kernel_size = 4, stride = 2, padding = 1, bias = False),\n",
    "            torch.nn.BatchNorm2d(self.down_dim*8),\n",
    "            torch.nn.LeakyReLU(0.2, inplace=True),\n",
    "            torch.nn.Conv2d(self.down_dim*8, self.down_dim*16, kernel_size = 4, stride = 2, padding = 1, bias = False),\n",
    "            torch.nn.BatchNorm2d(self.down_dim*16),\n",
    "            torch.nn.LeakyReLU(0.2, inplace=True),\n",
    "            torch.nn.Conv2d(self.down_dim*16, self.down_dim*32, kernel_size = 4, stride = 2, padding = 1, bias = False),\n",
    "            torch.nn.BatchNorm2d(self.down_dim*32),\n",
    "            torch.nn.LeakyReLU(0.2, inplace=True),\n",
    "            torch.nn.Conv2d(self.down_dim*32, self.down_dim*16, kernel_size = 3, stride = 1, padding = 1, bias = False),\n",
    "            torch.nn.BatchNorm2d(self.down_dim * 16),\n",
    "            torch.nn.LeakyReLU(0.2, inplace=True),\n",
    "            torch.nn.Conv2d(self.down_dim*16, self.down_dim*8, kernel_size = 3, stride = 1, padding = 1, bias = False),\n",
    "            torch.nn.BatchNorm2d(self.down_dim * 8),\n",
    "            torch.nn.LeakyReLU(0.2, inplace=True))   # 4 * 4 * ndf * 8)\n",
    "        \n",
    "        self.get_logits = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(self.down_dim*8+self.cond_dim, self.down_dim*8, kernel_size = 3, stride = 1, padding = 1, bias = False),\n",
    "            torch.nn.BatchNorm2d(self.down_dim*8),\n",
    "            torch.nn.LeakyReLU(0.2, inplace=True),\n",
    "            torch.nn.Conv2d(self.down_dim*8, 1, kernel_size = 4, stride = 4),\n",
    "            torch.nn.Sigmoid())\n",
    "        \n",
    "    def forward(self, image, cond_vec):\n",
    "        x = self.enc_img(image)\n",
    "        y = cond_vec.view(-1, self.cond_dim, 1, 1)\n",
    "        y = y.repeat(1,1,4,4)\n",
    "        z = torch.cat((x,y),1) # N x (128 + 512) x 4 x 4\n",
    "        out = self.get_logits(z).view(-1)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_s1(gen, disc, train_s1_imgs, train_s1_emds, batch_size=64, epochs=10, eta=0.0001, opt=optim.Adam,\n",
    "             model_name='A_Model_Has_No_Name', kl_lambda=2.0, embedding_dim=1024, cond_dim=128, GPU_List='0'):\n",
    "    gen.cuda()\n",
    "    disc.cuda()\n",
    "    \n",
    "    gpus = [int(x) for x in GPU_List.split(',')]\n",
    "    \n",
    "    optim_gen = opt(gen.parameters(), lr=eta)\n",
    "    optim_disc = opt(disc.parameters(), lr=eta)\n",
    "    \n",
    "    print('Training Stage 1...')\n",
    "    \n",
    "    l_tr_g = []\n",
    "    l_tr_d = []\n",
    "    iter_tr = []\n",
    "    \n",
    "    desc_shape = train_s1_emds[0].shape\n",
    "    img_shape = train_s1_imgs[0].shape\n",
    "    \n",
    "    file_path = \"./observations/\"\n",
    "    directory = os.path.dirname(file_path)\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    file_path = \"./saved_models/\"\n",
    "    directory = os.path.dirname(file_path)\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    ts = ts_ + \"_S1_\" + model_name\n",
    "    \n",
    "    real_pairs = []\n",
    "    for i in range(len(train_s1_imgs)):\n",
    "        for j in range(n_desc_per_img):\n",
    "            real_pairs.append((i,i * n_desc_per_img + j))\n",
    "    \n",
    "    n_train = len(real_pairs)\n",
    "    print('Training Size = ',n_train)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        l_tr_g_temp = 0\n",
    "        l_tr_d_temp = 0\n",
    "        \n",
    "        ############ Shuffle and Gen Fake Pairs ############\n",
    "        shuffle(real_pairs)\n",
    "        fake_pairs = []\n",
    "        for i in range(n_train):\n",
    "            nidx = randint(0,len(train_s1_emds)-1)\n",
    "            while nidx == real_pairs[i][1]:\n",
    "                nidx = randint(0,len(train_s1_emds)-1)\n",
    "            fake_pairs.append((real_pairs[i][0],nidx))\n",
    "        \n",
    "        ############ Training #############\n",
    "        start = 0\n",
    "        end = 0\n",
    "        while start < n_train:\n",
    "            end = start + batch_size\n",
    "            if end > n_train:\n",
    "                end = n_train\n",
    "            batch_size_ = end - start\n",
    "            \n",
    "            inp_img = [train_s1_imgs[x[0]] for x in real_pairs[start:end]]\n",
    "            inp_text = [train_s1_emds[x[1]] for x in real_pairs[start:end]]\n",
    "            inp_ftext = [train_s1_emds[x[1]] for x in fake_pairs[start:end]]\n",
    "            \n",
    "            real_img = Variable(torch.FloatTensor(inp_img).view(-1,img_shape[0],img_shape[1],img_shape[2])).type(torch.FloatTensor).cuda()\n",
    "            real_text = Variable(torch.FloatTensor(inp_text).view(-1,desc_shape[0])).cuda()\n",
    "            fake_text = Variable(torch.FloatTensor(inp_ftext).view(-1,desc_shape[0])).cuda()\n",
    "            \n",
    "            fake_img, mu, sigma = torch.nn.parallel.data_parallel(gen,(real_text),gpus)\n",
    "            \n",
    "            disc_real = torch.nn.parallel.data_parallel(disc,(real_img, mu),gpus)\n",
    "            disc_fake = torch.nn.parallel.data_parallel(disc,(fake_img, mu),gpus)\n",
    "            augm = cond_aug(embedding_dim, cond_dim)\n",
    "            augm.cuda()\n",
    "            mu_w, _, _ = augm(fake_text)\n",
    "            disc_wrong = torch.nn.parallel.data_parallel(disc,(real_img, mu_w),gpus)\n",
    "            \n",
    "            optim_gen.zero_grad()\n",
    "            optim_disc.zero_grad()\n",
    "            \n",
    "            ld_ = loss_disc(disc_real, disc_fake, disc_wrong, batch_size_)         \n",
    "            ld_.backward(retain_graph=True)\n",
    "            optim_disc.step()\n",
    "            lg_ = loss_gen(disc_fake, mu, sigma, kl_lambda, batch_size_)\n",
    "            lg_.backward(retain_graph=True)\n",
    "            optim_gen.step()\n",
    "            \n",
    "#             print(gen.ups_input.weight.grad)\n",
    "            \n",
    "            l_tr_g_temp += float(lg_.data)\n",
    "            l_tr_d_temp += float(ld_.data)\n",
    "            \n",
    "            del inp_img, inp_text, inp_ftext, real_img, real_text, fake_text, disc_real, disc_fake, augm, mu_w, disc_wrong, ld_, lg_, batch_size_\n",
    "            \n",
    "            start += batch_size\n",
    "            \n",
    "        l_tr_g.append(l_tr_g_temp/n_train)\n",
    "        l_tr_d.append(l_tr_d_temp/n_train)\n",
    "        iter_tr.append(epoch+1)\n",
    "        l = open('./observations/Loss_S1_'+ts+'.txt','a+')\n",
    "        l.write('Epoch ' + str(epoch) + ': Generator Loss = ' + str(l_tr_g_temp/n_train) + \\\n",
    "               '         Discriminator Loss = ' + str(l_tr_d_temp/n_train)  + '\\n')\n",
    "        print('Epoch ' + str(epoch) + ': Generator Loss = ' + str(l_tr_g_temp/n_train) + \\\n",
    "               '         Discriminator Loss = ' + str(l_tr_d_temp/n_train))\n",
    "        l.close()\n",
    "        \n",
    "        if os.path.exists('saved_models/gen_s1_' + str(ts) + '.pt'):\n",
    "            os.remove('saved_models/gen_s1_' + str(ts) + '.pt')\n",
    "            os.remove('saved_models/disc_s1_' + str(ts) + '.pt')\n",
    "        torch.save(gen,'saved_models/gen_s1_' + str(ts) + '.pt')\n",
    "        torch.save(disc,'saved_models/disc_s1_' + str(ts) + '.pt')\n",
    "    \n",
    "    return l_tr_g, l_tr_d\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_s2(gen, disc, gen_s1, train_s2_imgs, train_s2_emds, batch_size=64, epochs=10, eta=0.0001, opt=optim.Adam,\n",
    "             model_name='A_Model_Has_No_Name', kl_lambda=2.0, embedding_dim=1024, cond_dim=128, GPU_List='0'):\n",
    "    gen.cuda()\n",
    "    disc.cuda()\n",
    "    gen_s1.cuda()\n",
    "    \n",
    "    gpus = [int(x) for x in GPU_List.split(',')]\n",
    "    \n",
    "    optim_gen = opt(gen.parameters(), lr=eta)\n",
    "    optim_disc = opt(disc.parameters(), lr=eta)\n",
    "    \n",
    "    print('Training Stage 2...')\n",
    "    \n",
    "    l_tr_g = []\n",
    "    l_tr_d = []\n",
    "    iter_tr = []\n",
    "    \n",
    "    desc_shape = train_s2_emds[0].shape\n",
    "    img_shape = train_s2_imgs[0].shape\n",
    "    \n",
    "    file_path = \"./observations/\"\n",
    "    directory = os.path.dirname(file_path)\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    file_path = \"./saved_models/\"\n",
    "    directory = os.path.dirname(file_path)\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    ts = ts_ + \"_S1_\" + model_name\n",
    "    \n",
    "    real_pairs = []\n",
    "    for i in range(len(train_s2_imgs)):\n",
    "        for j in range(n_desc_per_img):\n",
    "            real_pairs.append((i,i * n_desc_per_img + j))\n",
    "    \n",
    "    n_train = len(real_pairs)\n",
    "    print('Training Size = ',n_train)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        l_tr_g_temp = 0\n",
    "        l_tr_d_temp = 0\n",
    "        \n",
    "        ############ Shuffle and Gen Fake Pairs ############\n",
    "        shuffle(real_pairs)\n",
    "        fake_pairs = []\n",
    "        for i in range(n_train):\n",
    "            nidx = randint(0,len(train_s2_emds)-1)\n",
    "            while nidx == real_pairs[i][1]:\n",
    "                nidx = randint(0,len(train_s2_emds)-1)\n",
    "            fake_pairs.append((real_pairs[i][0],nidx))\n",
    "        \n",
    "        ############ Training #############\n",
    "        start = 0\n",
    "        end = 0\n",
    "        while start < n_train:\n",
    "            end = start + batch_size\n",
    "            if end > n_train:\n",
    "                end = n_train\n",
    "            batch_size_ = end - start\n",
    "            \n",
    "            inp_img = [train_s2_imgs[x[0]] for x in real_pairs[start:end]]\n",
    "            inp_text = [train_s2_emds[x[1]] for x in real_pairs[start:end]]\n",
    "            inp_ftext = [train_s2_emds[x[1]] for x in fake_pairs[start:end]]\n",
    "            \n",
    "            real_img = Variable(torch.FloatTensor(inp_img).view(-1,img_shape[0],img_shape[1],img_shape[2])).type(torch.FloatTensor).cuda()\n",
    "            real_text = Variable(torch.FloatTensor(inp_text).view(-1,desc_shape[0])).cuda()\n",
    "            fake_text = Variable(torch.FloatTensor(inp_ftext).view(-1,desc_shape[0])).cuda()\n",
    "            \n",
    "            fake_s1, _, _ = torch.nn.parallel.data_parallel(gen_s1,(real_text),gpus)\n",
    "            fake_img, mu, sigma = torch.nn.parallel.data_parallel(gen,(real_text,fake_s1),gpus)\n",
    "            \n",
    "            disc_real = torch.nn.parallel.data_parallel(disc,(real_img, mu),gpus)\n",
    "            disc_fake = torch.nn.parallel.data_parallel(disc,(fake_img, mu),gpus)\n",
    "            augm = cond_aug(embedding_dim, cond_dim)\n",
    "            augm.cuda()\n",
    "            mu_w, _, _ = augm(fake_text)\n",
    "            disc_wrong = torch.nn.parallel.data_parallel(disc,(real_img, mu_w),gpus)\n",
    "            \n",
    "            optim_gen.zero_grad()\n",
    "            optim_disc.zero_grad()\n",
    "            \n",
    "            ld_ = loss_disc(disc_real, disc_fake, disc_wrong, batch_size_)         \n",
    "            ld_.backward(retain_graph=True)\n",
    "            optim_disc.step()\n",
    "            lg_ = loss_gen(disc_fake, mu, sigma, kl_lambda, batch_size_)\n",
    "            lg_.backward(retain_graph=True)\n",
    "            optim_gen.step()\n",
    "            \n",
    "            l_tr_g_temp += float(lg_.data)\n",
    "            l_tr_d_temp += float(ld_.data)\n",
    "            \n",
    "            del inp_img, inp_text, inp_ftext, real_img, real_text, fake_text, disc_real, disc_fake, augm, mu_w, disc_wrong, ld_, lg_, batch_size_\n",
    "            \n",
    "            start += batch_size\n",
    "            \n",
    "        l_tr_g.append(l_tr_g_temp/n_train)\n",
    "        l_tr_d.append(l_tr_d_temp/n_train)\n",
    "        iter_tr.append(epoch+1)\n",
    "        l = open('./observations/Loss_S1_'+ts+'.txt','a+')\n",
    "        l.write('Epoch ' + str(epoch) + ': Generator Loss = ' + str(l_tr_g_temp/n_train) + \\\n",
    "               '         Discriminator Loss = ' + str(l_tr_d_temp/n_train)  + '\\n')\n",
    "        print('Epoch ' + str(epoch) + ': Generator Loss = ' + str(l_tr_g_temp/n_train) + \\\n",
    "               '         Discriminator Loss = ' + str(l_tr_d_temp/n_train))\n",
    "        l.close()\n",
    "        \n",
    "        if os.path.exists('saved_models/gen_s2_' + str(ts) + '.pt'):\n",
    "            os.remove('saved_models/gen_s2_' + str(ts) + '.pt')\n",
    "            os.remove('saved_models/disc_s2_' + str(ts) + '.pt')\n",
    "        torch.save(gen,'saved_models/gen_s2_' + str(ts) + '.pt')\n",
    "        torch.save(disc,'saved_models/disc_s2_' + str(ts) + '.pt')\n",
    "    \n",
    "    return l_tr_g, l_tr_d\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_s1(gen, test_s1_emds, test_text, test_num = 500, random=True, model_name='A_Model_Has_No_Name', GPU_List='0', batch_size=4):\n",
    "    if test_num > len(test_s1_emds):\n",
    "        print(\"Too many test images!\")\n",
    "        return\n",
    "    \n",
    "    desc_shape = train_s1_emds[0].shape\n",
    "    ts = ts_ + \"_test_S1_\" + model_name\n",
    "    store_images_path = \"./observations/\" + ts + \"/\"\n",
    "    directory = os.path.dirname(store_images_path)\n",
    "\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    \n",
    "    num_batches = int(test_num/batch_size)\n",
    "    \n",
    "    for i in range(num_batches):\n",
    "        indx=0\n",
    "        text = []\n",
    "        indices=[]\n",
    "        \n",
    "        for count in range(batch_size):\n",
    "            if random == True:\n",
    "                indx=randint(0,len(test_s1_emds)-1)\n",
    "            else:\n",
    "                indx = i * batch_size + count\n",
    "            text.append(test_s1_emds[indx])\n",
    "            indices.append(indx)\n",
    "        \n",
    "        text = Variable(torch.FloatTensor(text).view(-1,desc_shape[0])).cuda()\n",
    "        imgs, _, _ = gen(text)\n",
    "        \n",
    "        imgs = (imgs + 1.0)*127.5\n",
    "        \n",
    "        for count in range(batch_size):\n",
    "            filename = test_text[indices[count]] + str(i * batch_size + count) + \".jpg\"\n",
    "            keepcharacters = (' ','.','_')\n",
    "            filename = \"\".join(c for c in filename if c.isalnum() or c in keepcharacters).rstrip()\n",
    "            if len(filename) > 250:\n",
    "                filename = filename[:250]\n",
    "            torchvision.utils.save_image(imgs[count].view(3,64,64), store_images_path + filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_s2(gen1, gen2, test_emds, test_text, test_num = 500, random=True, model_name='A_Model_Has_No_Name', GPU_List='0', batch_size=4):\n",
    "    if test_num > len(test_s1_emds):\n",
    "        print(\"Too many test images!\")\n",
    "        return\n",
    "    \n",
    "    desc_shape = train_s2_emds[0].shape\n",
    "    ts = ts_ + \"_test_S2_\" + model_name\n",
    "    store_images_path = \"./observations/\" + ts + \"/\"\n",
    "    directory = os.path.dirname(store_images_path)\n",
    "\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    \n",
    "    num_batches = int(test_num/batch_size)\n",
    "    \n",
    "    for i in range(num_batches):\n",
    "        indx=0\n",
    "        text = []\n",
    "        indices=[]\n",
    "        \n",
    "        for count in range(batch_size):\n",
    "            if random == True:\n",
    "                indx=randint(0,len(test_s1_emds)-1)\n",
    "            else:\n",
    "                indx = i * batch_size + count\n",
    "            text.append(test_s1_emds[indx])\n",
    "            indices.append(indx)\n",
    "        \n",
    "        text = Variable(torch.FloatTensor(text).view(-1,desc_shape[0])).cuda()\n",
    "        imgs_s1, _, _ = gen1(text)\n",
    "        imgs_s2, _, _ = gen2(text, imgs_s1)\n",
    "        \n",
    "        imgs_s2 = (imgs_s2 + 1.0)*127.5\n",
    "        \n",
    "        for count in range(batch_size):\n",
    "            filename = test_text[indices[count]] + str(i * batch_size + count) + \".jpg\"\n",
    "            keepcharacters = (' ','.','_')\n",
    "            filename = \"\".join(c for c in filename if c.isalnum() or c in keepcharacters).rstrip()\n",
    "            if len(filename) > 250:\n",
    "                filename = filename[:250]\n",
    "            torchvision.utils.save_image(imgs_s2[count].view(3,256,256), store_images_path + filename)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'CUB'\n",
    "f_s1_name = 'proc_data_transform_stage1.pickle'\n",
    "f_s2_name = 'proc_data_transform_stage2.pickle'\n",
    "addr_1 = dataset + '/' + f_s1_name\n",
    "addr_2 = dataset + '/' + f_s2_name\n",
    "print('Data Input ==>')\n",
    "if not os.path.exists(addr_1):\n",
    "    train_s1_imgs, train_s1_emds, test_s1_imgs, test_s1_emds, train_text, test_text = data_transform.read_input(dataset=dataset, stage=1)\n",
    "    train_s2_imgs, train_s2_emds, test_s2_imgs, test_s2_emds, train_text, test_text = data_transform.read_input(dataset=dataset, stage=2)\n",
    "    with open(addr_1,'wb') as f:\n",
    "        pickle.dump([train_s1_imgs, train_s1_emds, test_s1_imgs, test_s1_emds, train_text, test_text],f)\n",
    "    with open(addr_2,'wb') as f:\n",
    "        pickle.dump([train_s2_imgs, train_s2_emds, test_s2_imgs, test_s2_emds, train_text, test_text],f)\n",
    "else:\n",
    "    with open(addr_1,'rb') as f:\n",
    "        train_s1_imgs, train_s1_emds, test_s1_imgs, test_s1_emds, train_text, test_text = pickle.load(f)\n",
    "    with open(addr_2,'rb') as f:\n",
    "        train_s2_imgs, train_s2_emds, test_s2_imgs, test_s2_emds, train_text, test_text = pickle.load(f)\n",
    "\n",
    "print('Train_S1_Data : ',len(train_s1_imgs))\n",
    "print('Test_S1_Data : ',len(test_s1_imgs))\n",
    "print('Train_S2_Data : ',len(train_s2_imgs))\n",
    "print('Test_S2_Data : ',len(test_s2_imgs))\n",
    "print('Train_S1_Data : ',len(train_s1_emds))\n",
    "print('Test_S1_Data : ',len(test_s1_emds))\n",
    "print('Train_S2_Data : ',len(train_s2_emds))\n",
    "print('Test_S2_Data : ',len(test_s2_emds))\n",
    "print('Train_Text : ',len(train_text))\n",
    "print('Test_Text : ',len(test_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "epochs_s1 = 300\n",
    "epochs_s2 = 300\n",
    "eta_s1 = 0.0002\n",
    "eta_s2 = 0.0002\n",
    "opt = optim.Adam\n",
    "embedding_dim = 1024\n",
    "cond_dim = 128\n",
    "noise_dim = 100\n",
    "ups_input_dim = 1024\n",
    "down_dim = 128\n",
    "num_residuals = 4\n",
    "kl_lambda = 2.0\n",
    "model_name = 'Stg1_Only_Parallel'\n",
    "GPU_List = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_s1 = stage1_gen(embedding_dim=embedding_dim, cond_dim=cond_dim, noise_dim=noise_dim, ups_input_dim=ups_input_dim)\n",
    "disc_s1 = stage1_disc(cond_dim=cond_dim, down_dim=down_dim)\n",
    "gen_s2 = stage2_gen(down_dim=down_dim, embedding_dim=embedding_dim, cond_dim=cond_dim, num_residuals=num_residuals)\n",
    "disc_s2 = stage2_disc(cond_dim=cond_dim, down_dim=down_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "l_tr_g_s1, l_tr_d_s1 = train_s1(gen_s1, disc_s1, train_s1_imgs, train_s1_emds, batch_size=batch_size,\n",
    "            epochs=epochs_s1, eta=eta_s1, opt=opt, model_name=model_name, kl_lambda=kl_lambda,\n",
    "            embedding_dim=embedding_dim, cond_dim=cond_dim, GPU_List=GPU_List)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_tr_g_s2, l_tr_d_s2 = train_s2(gen_s2, disc_s2, gen_s1, train_s2_imgs, train_s2_emds, batch_size=batch_size,\n",
    "            epochs=epochs_s1, eta=eta_s1, opt=opt, model_name=model_name, kl_lambda=kl_lambda,\n",
    "            embedding_dim=embedding_dim, cond_dim=cond_dim, GPU_List=GPU_List)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = torch.load(\"gen_s1_2018-05-30__07h59m27s_S1_Stg1_Only_Parallel_Trial.pt\")\n",
    "test_s1(gen, test_s1_emds, test_text, test_num = 100, random=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
